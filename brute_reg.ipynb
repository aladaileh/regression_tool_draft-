{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304e24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler ,PolynomialFeatures\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split ,cross_val_score ,StratifiedKFold ,KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.linear_model import ElasticNet, BayesianRidge, HuberRegressor, Lars\n",
    "import itertools\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import time \n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7583d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_df = pd.read_csv(r\"C:\\Users\\97155\\Downloads\\inputs_df.csv\"  )\n",
    "inputs_df.set_index('CURVE_START_DT', inplace=True)\n",
    "x_parameters=['NEWC Fwd', 'JKM', 'ICE Brent Fwd (3-0-1)', 'GDP', 'Nuclear', 'Solar', 'HDDs', 'CDDs']\n",
    "y_parameter = 'power_mmcm'\n",
    "regression_start_date = '2019-01-01'\n",
    "regression_end_date = '2020-02-01'\n",
    "regression_degrees = 2\n",
    "num_duplicates = 2\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72bb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = inputs_df[(inputs_df.index >= regression_start_date) & (inputs_df.index <= regression_end_date)].copy()\n",
    "y_train = regression_df[y_parameter].values.reshape(-1,1)\n",
    "X_train = regression_df[x_parameters]\n",
    "y_train_duplicate = pd.concat([pd.DataFrame(y_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "X_train_duplicate = pd.concat([pd.DataFrame(X_train)] * num_duplicates, ignore_index=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0eb01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = inputs_df[x_parameters + [y_parameter]].dropna(subset=x_parameters, how='any')\n",
    "out_sample = forecast_df[(forecast_df.index < regression_start_date) | (forecast_df.index > regression_end_date)].dropna(how='any')\n",
    "y_test = out_sample[y_parameter].values.reshape(-1,1)\n",
    "X_test = out_sample[x_parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7f6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=regression_degrees, include_bias=False)\n",
    "scl = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "poly_features_train = poly_reg.fit_transform(X_train)\n",
    "scal_features_train = scl.fit_transform(X_train)\n",
    "scal_poly_features_train = poly_reg.fit_transform(scal_features_train)\n",
    "\n",
    "poly_features_test = poly_reg.fit_transform(X_test)\n",
    "scal_features_test = scl.fit_transform(X_test)\n",
    "scal_poly_features_test = poly_reg.fit_transform(scal_features_test)\n",
    "\n",
    "poly_features_train_duplicate = poly_reg.fit_transform(X_train_duplicate)\n",
    "scal_features_train_duplicate = scl.fit_transform(X_train_duplicate)\n",
    "scal_poly_features_train_duplicate = poly_reg.fit_transform(scal_features_train_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e8bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()\n",
    "rf_regressor = RandomForestRegressor(n_estimators=450, random_state=seed)\n",
    "lin_reg_model = LinearRegression()\n",
    "alpha = 0.1  # L1 regularization strength\n",
    "l1_ratio = 0.5  # Mixing parameter (0.5 for an equal mix of L1 and L2)\n",
    "elnt_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "bays_model = BayesianRidge()\n",
    "Hur_model = HuberRegressor(epsilon=1.35)\n",
    "Lars_model = Lars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e5b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_lock = threading.Lock()\n",
    "\n",
    "def GitScore(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    score = model.score(x_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4c6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_unique_dates(start_date, end_date):\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    dates_delta = relativedelta(end_date, start_date)\n",
    "    num_months = dates_delta.months + (dates_delta.years * 12) + 1\n",
    "    dates_list = []\n",
    "    for i in range(num_months):\n",
    "        d1 = start_date + relativedelta(months=i)\n",
    "        for k in range(i, num_months):\n",
    "            d2 = start_date + relativedelta(months=k)            \n",
    "            dates_list.append([d1, d2])\n",
    "    return dates_list\n",
    "\n",
    "start_date = '2018-01-01'\n",
    "end_date= '2023-04-01'\n",
    "\n",
    "dates_list= get_reg_unique_dates(start_date, end_date)\n",
    "\n",
    "\n",
    "filtered_dates_list = []\n",
    "for i in dates_list:\n",
    "    if datetime.strptime(str(i[0]),\"%Y-%m-%d %H:%M:%S\").year != datetime.strptime(str(i[1]),\"%Y-%m-%d %H:%M:%S\").year:\n",
    "        filtered_dates_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02975ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[rf_regressor,lin_reg_model,svr_model ,elnt_model, bays_model]\n",
    "\n",
    "xs = ['HDDs', 'CDDs', 'NEWC Fwd', 'JKM', 'ICE Brent Fwd (3-0-1)', 'GDP', 'Nuclear', 'Solar']\n",
    "xs_list = []\n",
    "num_xs = len(xs)\n",
    "\n",
    "for i in range(len(xs) + 1):\n",
    "    for subset in itertools.combinations(xs, i):\n",
    "        # print(subset)\n",
    "        #if len(subset) > 0:\n",
    "        xs_list.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51fd41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(input_list, n):\n",
    "    # Calculate the number of elements in each sublist\n",
    "    sublist_size = len(input_list) // n\n",
    "    remainder = len(input_list) % n\n",
    "\n",
    "    # Initialize variables\n",
    "    sublists = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        # Calculate the end index for the current sublist\n",
    "        end = start + sublist_size + (1 if i < remainder else 0)\n",
    "\n",
    "        # Append the sublist to the result\n",
    "        sublists.append(input_list[start:end])\n",
    "\n",
    "        # Update the start index for the next sublist\n",
    "        start = end\n",
    "\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f0d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_preparing(filtered_dates_list_1, shared_dict, time_range, lock):\n",
    "\n",
    "#     for i in filtered_dates_list_1:\n",
    "#         regression_start_date = i[0]\n",
    "#         regression_end_date = i[1]\n",
    "#         regression_df = inputs_df[(inputs_df.index >= str(regression_start_date)) & (inputs_df.index <= str(regression_end_date))].dropna(how='any').copy()\n",
    "#         y_train = regression_df[y_parameter].values.reshape(-1,1)\n",
    "#         X_train = regression_df[x_parameters]\n",
    "    \n",
    "#         forecast_df = inputs_df[x_parameters + [y_parameter]].dropna(subset=x_parameters, how='any')\n",
    "#         out_sample = forecast_df[(forecast_df.index < str(regression_start_date)) | (forecast_df.index > str(regression_end_date))].dropna(how='any')\n",
    "#         y_test = out_sample[y_parameter].values.reshape(-1,1)\n",
    "#         X_test = out_sample[x_parameters]\n",
    "#         y_train_duplicate = pd.concat([pd.DataFrame(y_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "#         X_train_duplicate = pd.concat([pd.DataFrame(X_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "\n",
    "#         poly_reg = PolynomialFeatures(degree=regression_degrees, include_bias=False)\n",
    "#         scl = MinMaxScaler(feature_range=(0, 1))\n",
    "#         changing = {}\n",
    "#         if X_train.shape[0] !=0:\n",
    "#             poly_features_train = poly_reg.fit_transform(X_train)\n",
    "#             scal_features_train = scl.fit_transform(X_train)\n",
    "#             scal_poly_features_train = poly_reg.fit_transform(scal_features_train)\n",
    "        \n",
    "#             poly_features_test = poly_reg.fit_transform(X_test)\n",
    "#             scal_features_test = scl.fit_transform(X_test)\n",
    "#             scal_poly_features_test = poly_reg.fit_transform(scal_features_test)\n",
    "        \n",
    "#             poly_features_train_duplicate = poly_reg.fit_transform(X_train_duplicate)\n",
    "#             scal_features_train_duplicate = scl.fit_transform(X_train_duplicate)\n",
    "#             scal_poly_features_train_duplicate = poly_reg.fit_transform(scal_features_train_duplicate)\n",
    "                    \n",
    "#             x_train_types = {'X_train': X_train, \n",
    "#                              'scal_features_train': scal_features_train,\n",
    "#                              'poly_features_train': poly_features_train,\n",
    "#                              'scal_poly_features_train': scal_poly_features_train}\n",
    "            \n",
    "#             x_test_types = [X_test, scal_features_test, poly_features_test, scal_poly_features_test]\n",
    "            \n",
    "#             x_train_dupl_types = {'X_train_duplicate': X_train_duplicate, \n",
    "#                                   'scal_features_train_duplicate': scal_features_train_duplicate,\n",
    "#                                   'poly_features_train_duplicate': poly_features_train_duplicate,\n",
    "#                                   'scal_poly_features_train_duplicate': scal_poly_features_train_duplicate}\n",
    "            \n",
    "#             y_train_types = [y_train, y_train_duplicate]\n",
    "#             for i in models:\n",
    "#                 scores = {}\n",
    "#                 for j in range(len(x_test_types)):\n",
    "#                     lock.acquire()\n",
    "#                     s_x= {}\n",
    "#                     s_x_dupl= {}\n",
    "#                     score_x = GitScore(i, list(x_train_types.values())[j], y_train, x_test_types[j], y_test)\n",
    "#                     score_x_dupl = GitScore(i, list(x_train_dupl_types.values())[j], y_train_duplicate, x_test_types[j], y_test)\n",
    "#                     s_x[f'{list(x_train_types.keys())[j]}'] = score_x\n",
    "#                     s_x_dupl[f'{list(x_train_dupl_types.keys())[j]}'] =  score_x_dupl\n",
    "                    \n",
    "#                     scores.update(s_x)\n",
    "#                     scores.update(s_x_dupl)\n",
    "#                     lock.release()\n",
    "#                 changing[f'{i}'] = scores\n",
    "#             time_range[f'{regression_start_date} _ {regression_end_date}']=changing\n",
    "#         else:\n",
    "#             pass\n",
    "#         shared_dict[str(x_parameters)]=time_range\n",
    "#         with lock:\n",
    "#             return shared_dict\n",
    "       \n",
    "            \n",
    "            \n",
    "# if __name__ == '__main__':\n",
    "#     xs_list_1= xs_list[37:]\n",
    "#     xs_list_2 = xs_list_1[0:1]\n",
    "#     for x_par in xs_list_2:\n",
    "#         lock = multiprocessing.Lock()\n",
    "#         filtered_dates_list_1 = filtered_dates_list[0:20]\n",
    "#         x_parameters = list(x_par)\n",
    "#         time_range = {}\n",
    "\n",
    "#         filtered_dates_list_splitted = split_list(filtered_dates_list_1, 2)\n",
    "#         threads = []\n",
    "\n",
    "#         for dates_list in filtered_dates_list_splitted:\n",
    "#             manager = multiprocessing.Manager()\n",
    "#             shared_dict = manager.dict()\n",
    "#             time_range = manager.dict()\n",
    "#             thread = multiprocessing.Process(target=data_preparing, args=(dates_list, shared_dict, time_range,lock))\n",
    "#             threads.append(thread)\n",
    "#             thread.start()\n",
    "     \n",
    "#         for thread in threads:\n",
    "#             thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31450ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shared_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa418ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_preparing(filtered_dates_list_1):\n",
    "#     lock = multiprocessing.Lock()\n",
    "#     for i in filtered_dates_list_1:\n",
    "#         regression_start_date = i[0]\n",
    "#         regression_end_date = i[1]\n",
    "#         regression_df = inputs_df[(inputs_df.index >= str(regression_start_date)) & (inputs_df.index <= str(regression_end_date))].dropna(how='any').copy()\n",
    "#         y_train = regression_df[y_parameter].values.reshape(-1,1)\n",
    "#         X_train = regression_df[x_parameters]\n",
    "    \n",
    "#         forecast_df = inputs_df[x_parameters + [y_parameter]].dropna(subset=x_parameters, how='any')\n",
    "#         out_sample = forecast_df[(forecast_df.index < str(regression_start_date)) | (forecast_df.index > str(regression_end_date))].dropna(how='any')\n",
    "#         y_test = out_sample[y_parameter].values.reshape(-1,1)\n",
    "#         X_test = out_sample[x_parameters]\n",
    "#         y_train_duplicate = pd.concat([pd.DataFrame(y_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "#         X_train_duplicate = pd.concat([pd.DataFrame(X_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "\n",
    "#         poly_reg = PolynomialFeatures(degree=regression_degrees, include_bias=False)\n",
    "#         scl = MinMaxScaler(feature_range=(0, 1))\n",
    "#         changing = {}\n",
    "#         if X_train.shape[0] !=0:\n",
    "#             poly_features_train = poly_reg.fit_transform(X_train)\n",
    "#             scal_features_train = scl.fit_transform(X_train)\n",
    "#             scal_poly_features_train = poly_reg.fit_transform(scal_features_train)\n",
    "        \n",
    "#             poly_features_test = poly_reg.fit_transform(X_test)\n",
    "#             scal_features_test = scl.fit_transform(X_test)\n",
    "#             scal_poly_features_test = poly_reg.fit_transform(scal_features_test)\n",
    "        \n",
    "#             poly_features_train_duplicate = poly_reg.fit_transform(X_train_duplicate)\n",
    "#             scal_features_train_duplicate = scl.fit_transform(X_train_duplicate)\n",
    "#             scal_poly_features_train_duplicate = poly_reg.fit_transform(scal_features_train_duplicate)\n",
    "                    \n",
    "#             x_train_types = {'X_train': X_train, \n",
    "#                              'scal_features_train': scal_features_train,\n",
    "#                              'poly_features_train': poly_features_train,\n",
    "#                              'scal_poly_features_train': scal_poly_features_train}\n",
    "            \n",
    "#             x_test_types = [X_test, scal_features_test, poly_features_test, scal_poly_features_test]\n",
    "            \n",
    "#             x_train_dupl_types = {'X_train_duplicate': X_train_duplicate, \n",
    "#                                   'scal_features_train_duplicate': scal_features_train_duplicate,\n",
    "#                                   'poly_features_train_duplicate': poly_features_train_duplicate,\n",
    "#                                   'scal_poly_features_train_duplicate': scal_poly_features_train_duplicate}\n",
    "            \n",
    "#             y_train_types = [y_train, y_train_duplicate]\n",
    "#             for i in models:\n",
    "#                 scores = {}\n",
    "#                 for j in range(len(x_test_types)):\n",
    "#                     lock.acquire()\n",
    "#                     s_x= {}\n",
    "#                     s_x_dupl= {}\n",
    "#                     score_x = GitScore(i, list(x_train_types.values())[j], y_train, x_test_types[j], y_test)\n",
    "#                     score_x_dupl = GitScore(i, list(x_train_dupl_types.values())[j], y_train_duplicate, x_test_types[j], y_test)\n",
    "#                     s_x[f'{list(x_train_types.keys())[j]}'] = score_x\n",
    "#                     s_x_dupl[f'{list(x_train_dupl_types.keys())[j]}'] =  score_x_dupl\n",
    "                    \n",
    "#                     scores.update(s_x)\n",
    "#                     scores.update(s_x_dupl)\n",
    "#                     lock.release()\n",
    "#                 changing[f'{i}'] = scores\n",
    "#             time_range[f'{regression_start_date} _ {regression_end_date}']=changing\n",
    "#         else:\n",
    "#             pass\n",
    "#         with lock:\n",
    "#             shared_dict[str(x_parameters)]=time_range\n",
    "#         return shared_dict\n",
    "       \n",
    "# if __name__ == '__main__':\n",
    "#     xs_list_1 = xs_list[37:]\n",
    "#     xs_list_2 = xs_list_1[0:1]\n",
    "#     filtered_dates_list_1 = filtered_dates_list[0:20]\n",
    "\n",
    "#     p = Pool()\n",
    "#     results = p.map(data_preparing, filtered_dates_list_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ec0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = multiprocessing.Lock()\n",
    "time_range={}\n",
    "fearure_secl= {}\n",
    "def data_preparing(filtered_dates_list_1, x_parameters ,shared_dict, lock):\n",
    "    \n",
    "    for i in filtered_dates_list_1:\n",
    "        regression_start_date = i[0]\n",
    "        regression_end_date = i[1]\n",
    "        regression_df = inputs_df[(inputs_df.index >= str(regression_start_date)) & (inputs_df.index <= str(regression_end_date))].dropna(how='any').copy()\n",
    "        y_train = regression_df[y_parameter].values.reshape(-1,1)\n",
    "        X_train = regression_df[x_parameters]\n",
    "    \n",
    "        forecast_df = inputs_df[x_parameters + [y_parameter]].dropna(subset=x_parameters, how='any')\n",
    "        out_sample = forecast_df[(forecast_df.index < str(regression_start_date)) | (forecast_df.index > str(regression_end_date))].dropna(how='any')\n",
    "        y_test = out_sample[y_parameter].values.reshape(-1,1)\n",
    "        X_test = out_sample[x_parameters]\n",
    "        y_train_duplicate = pd.concat([pd.DataFrame(y_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "        X_train_duplicate = pd.concat([pd.DataFrame(X_train)] * num_duplicates, ignore_index=True,axis=0)\n",
    "  \n",
    "        poly_reg = PolynomialFeatures(degree=regression_degrees, include_bias=False)\n",
    "        scl = MinMaxScaler(feature_range=(0, 1))\n",
    "        changing = {}\n",
    "        if X_train.shape[0] !=0:\n",
    "            poly_features_train = poly_reg.fit_transform(X_train)\n",
    "            scal_features_train = scl.fit_transform(X_train)\n",
    "            scal_poly_features_train = poly_reg.fit_transform(scal_features_train)\n",
    "        \n",
    "            poly_features_test = poly_reg.fit_transform(X_test)\n",
    "            scal_features_test = scl.fit_transform(X_test)\n",
    "            scal_poly_features_test = poly_reg.fit_transform(scal_features_test)\n",
    "        \n",
    "            poly_features_train_duplicate = poly_reg.fit_transform(X_train_duplicate)\n",
    "            scal_features_train_duplicate = scl.fit_transform(X_train_duplicate)\n",
    "            scal_poly_features_train_duplicate = poly_reg.fit_transform(scal_features_train_duplicate)\n",
    "                    \n",
    "            x_train_types = {'X_train': X_train, \n",
    "                             'scal_features_train': scal_features_train,\n",
    "                             'poly_features_train': poly_features_train,\n",
    "                             'scal_poly_features_train': scal_poly_features_train}\n",
    "            \n",
    "            x_test_types = [X_test, scal_features_test, poly_features_test, scal_poly_features_test]\n",
    "            \n",
    "            x_train_dupl_types = {'X_train_duplicate': X_train_duplicate, \n",
    "                                  'scal_features_train_duplicate': scal_features_train_duplicate,\n",
    "                                  'poly_features_train_duplicate': poly_features_train_duplicate,\n",
    "                                  'scal_poly_features_train_duplicate': scal_poly_features_train_duplicate}\n",
    "            \n",
    "            y_train_types = [y_train, y_train_duplicate]\n",
    "            for i in models:\n",
    "                scores = {}\n",
    "                for j in range(len(x_test_types)):\n",
    "                    lock.acquire()\n",
    "                    s_x= {}\n",
    "                    s_x_dupl= {}\n",
    "                    score_x = GitScore(i, list(x_train_types.values())[j], y_train, x_test_types[j], y_test)\n",
    "                    score_x_dupl = GitScore(i, list(x_train_dupl_types.values())[j], y_train_duplicate, x_test_types[j], y_test)\n",
    "                    s_x[f'{list(x_train_types.keys())[j]}'] = score_x\n",
    "                    s_x_dupl[f'{list(x_train_dupl_types.keys())[j]}'] =  score_x_dupl\n",
    "                    \n",
    "                    scores.update(s_x)\n",
    "                    scores.update(s_x_dupl)\n",
    "                    lock.release()\n",
    "                changing[f'{i}'] = scores\n",
    "            time_range[f'{regression_start_date} _ {regression_end_date}']=changing\n",
    "        else:\n",
    "            pass\n",
    "        fearure_secl[str(x_parameters)]=time_range\n",
    "        with lock:\n",
    "            shared_dict=fearure_secl\n",
    "            \n",
    "def combinations_preparing(x_parameters, filtered_dates_list):\n",
    "    manager = multiprocessing.Manager()\n",
    "    shared_dict = manager.dict()\n",
    "    lock = manager.Lock()\n",
    "    \n",
    "    threads = []\n",
    "\n",
    "    for dates_list in filtered_dates_list:\n",
    "        thread = multiprocessing.Process(target=data_preparing, args=(dates_list, x_parameters, shared_dict, lock))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    return shared_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xs_list_1 = xs_list[37:]\n",
    "    xs_list_2 = xs_list_1[0:10]\n",
    "    filtered_dates_list_1 = filtered_dates_list[0:20]\n",
    "\n",
    "    p = Pool()\n",
    "    results = p.starmap(combinations_preparing, [(x_par, filtered_dates_list_1) for x_par in xs_list_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9454a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
